{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docs : https://weaviate.io/developers/weaviate/client-libraries/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run `docker-compose up -d` for local deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from utils import load_documents,split_documents,calculate_chunk_ids\n",
    "\n",
    "import weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721788533.744750   13998 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# v3\n",
    "# # Option #1 - Self-hosted - Weaviate Open Source \n",
    "# client = weaviate.Client(\n",
    "#     url=\"http://localhost:8080\",\n",
    "#     additional_headers={\n",
    "#         \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# v4\n",
    "client = weaviate.connect_to_local(\n",
    "    host=\"localhost\",\n",
    "    port=8080,\n",
    ") \n",
    "\n",
    "# WEAVIATE_ADMIN_BEARER_TOKEN = os.getenv(\"WEAVIATE_ADMIN\")\n",
    "# WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\")\n",
    "# ## Option #2 - SaaS - (Weaviate Cloud Service)\n",
    "# client = weaviate.Client(\n",
    "#     url= WEAVIATE_URL, # Expires in 14 days : Free Tier\n",
    "#     auth_client_secret=weaviate.auth.AuthApiKey(api_key=WEAVIATE_ADMIN_BEARER_TOKEN),\n",
    "#     additional_headers={\n",
    "#         \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_schema = {\n",
    "    \"class\": \"Chunk\",\n",
    "    \"description\": \"A collection of context and related embeddings\",\n",
    "    \"vectorizer\": \"text2vec-openai\",\n",
    "    \"moduleConfig\": {\n",
    "        \"text2vec-openai\": {\n",
    "          \"model\": \"ada\",\n",
    "          \"modelVersion\": \"002\",\n",
    "          \"type\": \"text\"\n",
    "        }\n",
    "    },\n",
    "    \"properties\": [\n",
    "    {\n",
    "        \"name\": \"context\",\n",
    "        \"description\": \"Context chunk from a pdf\",\n",
    "        \"dataType\": [\"text\"],\n",
    "        \"moduleConfig\": { \n",
    "            \"text2vec-openai\": { \n",
    "                \"skip\": True \n",
    "            } \n",
    "        }\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_documents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'source': '../../data/Galapagos/pdfs/CnE_GUI-CE-027 Guidance on Declaration of Interest (1).pdf',\n",
       "  'page': 0},\n",
       " 'Do you need to\\n(Also known as a Conflict of Interest)DECLARE AN INTEREST?\\nYou may need to declare an interest where a potential conflict arises…\\nA potential conflict of interest just means that your personal interests could conflict with your role and decisions at \\nGalapagos. \\nIt doesn’t mean that there is an actual conflict or that you’ve done anything wrong. In fact, conflicts are usually a \\nresult of good things — like having good relationships through friendships or investments. \\nBut they could also be perceived by someone else as impacting your judgment, or could harm the trust between \\ncolleagues, and that’s why we need to be aware of them so we can take any steps we need to manage them. \\nHere are some examples…\\nWhat should I do if I think I might need to declare an interest?')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].metadata,chunks[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = calculate_chunk_ids(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/Galapagos/pdfs/CnE_GUI-CE-027 Guidance on Declaration of Interest (1).pdf:0:0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].metadata['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import openai\n",
    "\n",
    "# Load environment variables\n",
    "OPENAI_ORG = os.getenv('OPENAI_ORG')\n",
    "OPENAI_APIKEY = os.getenv('OPENAI_APIKEY')\n",
    "\n",
    "openai.organization = OPENAI_ORG\n",
    "openai.api_key = OPENAI_APIKEY\n",
    "\n",
    "\n",
    "openai_client = openai.OpenAI(api_key=OPENAI_APIKEY)\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai_client.embeddings.create(input = [text], model=model).data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'message': 'Failed to send 1 references in a batch of 1. Please inspect client.batch.failed_references or collection.batch.failed_references for the failed references.', 'errors': {0: ErrorReference(message='property linkedChunk does not exist for class Chunk', reference=_BatchReference(from_='weaviate://localhost/Chunk/c28f441b-9830-4d68-9d79-b3da72c65931/linkedChunk', to='weaviate://localhost/a5c666b4-e05c-438c-a13c-2290eace8d06', tenant=None, from_uuid='c28f441b-9830-4d68-9d79-b3da72c65931', to_uuid='a5c666b4-e05c-438c-a13c-2290eace8d06'))}}\n"
     ]
    }
   ],
   "source": [
    "# Uploading data with vectors to Chunk schema\n",
    "counter=0\n",
    "import uuid\n",
    "with client.batch.dynamic() as batch:\n",
    "    initial_uuid = None\n",
    "    latest_uuid = None\n",
    "    for chunk in chunks:\n",
    "        chunk_id = chunk.metadata['id']\n",
    "        chunk_content = chunk.page_content\n",
    "        properties = {\n",
    "            \"context\": chunk_content\n",
    "        }\n",
    "        _uuid = uuid.uuid4()\n",
    "        if not initial_uuid:\n",
    "            initial_uuid = _uuid\n",
    "        latest_uuid = _uuid\n",
    "        vector = get_embedding(chunk_content)\n",
    "        batch.add_object(properties={\n",
    "            chunk_schema['properties'][0]['name'] : chunk_content,\n",
    "            },\n",
    "            collection=chunk_schema['class'],\n",
    "            uuid=_uuid\n",
    "        )\n",
    "        counter = counter+1\n",
    "    batch.add_reference(from_collection=chunk_schema['class'], from_uuid=initial_uuid, from_property=\"linkedChunk\", to=latest_uuid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing (494) chunks complete\n"
     ]
    }
   ],
   "source": [
    "assert counter == len(chunks)\n",
    "print(f\"Importing ({len(chunks)}) chunks complete\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (\n",
    "    client.query.aggregate(\"Chunk\")\n",
    "    .with_fields(\"meta { count }\")\n",
    "    .do()\n",
    ")\n",
    "print(\"Object count: \", result[\"data\"][\"Aggregate\"][\"Chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test one article has worked by checking one object\n",
    "test_article = (\n",
    "    client.query\n",
    "    .get(\"Chunk\", [\"context\", \"_additional {id}\"])\n",
    "    .with_limit(1)\n",
    "    .do()\n",
    ")[\"data\"][\"Get\"][\"Chunk\"][0]\n",
    "\n",
    "print(test_article[\"_additional\"][\"id\"])\n",
    "print(test_article[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_weaviate(query, collection_name, top_k=5):\n",
    "\n",
    "    # Creates embedding vector from user query\n",
    "    embedded_query = get_embedding(query)\n",
    "    \n",
    "    near_vector = {\"vector\": embedded_query}\n",
    "\n",
    "    # Queries input schema with vectorised user query\n",
    "    query_result = (\n",
    "        client.query\n",
    "        .get(collection_name, [\"context\", \"_additional {certainty distance}\"])\n",
    "        .with_near_vector(near_vector)\n",
    "        .with_limit(top_k)\n",
    "        .do()\n",
    "    )\n",
    "    \n",
    "    return query_result\n",
    "\n",
    "\n",
    "#  Possibility to \"Let Weaviate handle vector embeddings\"\n",
    "\n",
    "def near_text_weaviate(query, collection_name):\n",
    "    \n",
    "    nearText = {\n",
    "        \"concepts\": [query],\n",
    "        \"distance\": 0.7,\n",
    "    }\n",
    "\n",
    "    properties = [\n",
    "        \"title\", \"context\",\n",
    "        \"_additional {certainty distance}\"\n",
    "    ]\n",
    "\n",
    "    query_result = (\n",
    "        client.query\n",
    "        .get(collection_name, properties)\n",
    "        .with_near_text(nearText)\n",
    "        .with_limit(20)\n",
    "        .do()\n",
    "    )[\"data\"][\"Get\"][collection_name]\n",
    "    \n",
    "    print (f\"Objects returned: {len(query_result)}\")\n",
    "    \n",
    "    return query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = query_weaviate(\"How to behave during a meeting?\", \"Chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"result.json\",\"w\") as f:\n",
    "    json.dump(query_result,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_results(query_result):\n",
    "    combined_result = ''\n",
    "    for result in query_result['data']['Get']['Chunk']:\n",
    "        combined_result += result['context'] +\"\\n\\n\"\n",
    "    return combined_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_context = get_combined_results(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_QUERY = \"How to behave during a meeting?\"\n",
    "RETREIVER_K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_USER_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "Question :\n",
    "{question}\n",
    "\n",
    "\n",
    "Context :\n",
    "{context}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an ICF MCC certified coach who has a lot of experience with life coaching.\n",
    "You are give certain context and a question. Use the context and output an answer that is precise and clear.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_query = PROMPT_USER_TEMPLATE.format(context=related_context, question=USER_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o\"\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt_query}\n",
    "    ],\n",
    ")\n",
    "assistant_message = response.choices[0].message.content\n",
    "tokens = response.usage.total_tokens\n",
    "assistant_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "'|   1ATTENDEES - Best meeting practices\n",
    "•Decide if you are joining the meeting\n",
    "\\uf0fcRSVP (respond) to the meeting organizer as soon as possible\n",
    "•Prepare: read the agenda and the pre- work\n",
    "\\uf0fccheck tasks from last meeting, prepare insights and /or questions\n",
    "•Be on time\n",
    "•Be present, participate and avoid distractions\n",
    "\\uf0fcturn off notifications, put away your phone\n",
    "•Make sure you are heard, even if your opinion is less popular \n",
    "•Reflect: did I participate, and did I share my opinion?\n",
    "•Provide feedback to the meeting organizer for potential improvement\n",
    "•Read and review the minutes \n",
    "•Check the follow -up tasks and act on yours\n",
    "Before\n",
    "During\n",
    "After\n",
    "\n",
    "|   1ORGANIZERS - Best meeting practices\n",
    "•Decide if you really need the meeting and select correct meeting type\n",
    "•Define a clear and timed agenda, including the meeting objective\n",
    "•Use the Outlook Scheduling Assistant to plan at an appropriate time\n",
    "•Carefully choose the attendees, share the agenda and materials in advance\n",
    "•Start by introducing people, stating the objective, and showing the agenda\n",
    "•Assign note -taker and timekeeper, but record tasks yourself\n",
    "•Moderate and ensure a safe space for everyone to get the word\n",
    "•End meeting by summarizing the follow -up tasks for all attendees\n",
    "•Share with all attendees the follow -up tasks and the meeting minutes\n",
    "•Reflect: was the meeting goal achieved, and was everyone heard?\n",
    "•Ensure follow -up and plan next meeting if necessary\n",
    "Before\n",
    "During\n",
    "After\n",
    "\n",
    "Tips for engaging and inclusive meetings\n",
    "☑Build trust and encourage participation\n",
    "|   1•assign minutes -taker and time -keeper roles\n",
    "•send the agenda (and pre -work) to the attendees in advance\n",
    "•keep it focused and engaging\n",
    "\\uf0d8be well -prepared to retain attendees’ attention \n",
    "\\uf0d8keep the meeting as short as possible\n",
    "\\uf0d8use polls, ratings, and whiteboards\n",
    "\\uf0d8establish ground rules at the start of the meeting\n",
    "•has everyone’s point of view been heard?\n",
    "\\uf0d8ask questions to prompt discussion and listen actively\n",
    "\n",
    "Time Management tips for Effective Meetings\n",
    "☑Respect other people’s time\n",
    "|   1•respond to meeting invites as soon as you receive them\n",
    "•reschedule timely to resolve meeting conflicts\n",
    "•don’t be afraid to politely decline a meeting\n",
    "(are you needed there? ask for an agenda, align expectations)\n",
    "☑Save yourself some time\n",
    "•share your calendar titles with your functional and TA teams\n",
    "•book well in advance long, recurring, and team meetings\n",
    "•respect time -zones and working hours, yours included!\n",
    "\n",
    "Calendar Man agement tips for Effective Meetings\n",
    "|   1☑Organ ize your calendar\n",
    "•state your working hours (e.g. 09:00-1 7:00)\n",
    "•change default meeting duration to 25’ instead of 30’\n",
    "•book lunch and travel time as OOO\n",
    "•book focus time as ‘tentative’ to avoid blocking your entire agenda\n",
    "☑Organi ze y our calenda r for OOO days\n",
    "•add public holidays for all major GLPG sites (single action)\n",
    "•enter your vacation on Outlook well in advance\n",
    "•reschedule (or decline) meetings happening during your absence\n",
    "\n",
    "'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "'During a meeting, you should:\n",
    "\n",
    "1. Be on time.\n",
    "2. Be present and actively participate, avoiding distractions such as phone notifications.\n",
    "3. Ensure you are heard, even if your opinions are less popular.\n",
    "4. Reflect on your participation and whether you shared your opinion.\n",
    "5. Provide feedback to the meeting organizer for potential improvements.\n",
    "'\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
